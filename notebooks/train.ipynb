{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raunakk/miniconda3/envs/msc_project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import d3rlpy\n",
    "from d3rlpy.datasets import get_d4rl\n",
    "import gym\n",
    "from d3rlpy.metrics.scorer import evaluate_on_environment\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ['D4RL_SUPPRESS_IMPORT_ERROR'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--task TASK] [--algo ALGO]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9008 --control=9006 --hb=9005 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"9e8c588e-7ee3-41ea-b19d-c84d6b03e25b\" --shell=9007 --transport=\"tcp\" --iopub=9009 --f=/home/raunakk/.local/share/jupyter/runtime/kernel-v2-23007p03Mm7VoJj4E.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--task\", type=str, help=\"task/game to be played\")\n",
    "parser.add_argument(\"--algo\", type=str, help=\"algorithm to be used for training\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "task = args.task #['HalfCheetah-v4', 'Walker2d-v4', 'Ant-v4']\n",
    "algo = args.algo\n",
    "print(task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MODEL():\n",
    "    def __init__(self, task, algo, gpu=True):\n",
    "        self.mean_results = []\n",
    "        self.task = task \n",
    "        self.algo = algo\n",
    "        self.f_params = {\"use_gpu\": gpu}\n",
    "        self.engine = None\n",
    "\n",
    "    def set_engine(self):\n",
    "        if self.algo == \"IQL\":\n",
    "            self.engine = d3rlpy.algos.IQL(**self.f_params)\n",
    "\n",
    "        elif self.algo == \"CQL\":\n",
    "            self.f_params[\"actor_learning_rate\"] = 3e-5\n",
    "            self.engine = d3rlpy.algos.CQL(**self.f_params)\n",
    "\n",
    "        elif self.algo == \"MOPO\":\n",
    "            self.engine = d3rlpy.algos.MOPO(**self.f_params)\n",
    "            \n",
    "        elif self.algo == \"COMBO\":\n",
    "            self.engine = d3rlpy.algos.COMBO(**self.f_params)\n",
    "\n",
    "    def train(self, n=100, n_steps=1000000, save_interval=100, save_metrics=False, verbose=False):\n",
    "        dataset, env = get_d4rl(self.task)\n",
    "        online_env = gym.make(self.task)\n",
    "        for i in range(n):\n",
    "            d3rlpy.seed(i)\n",
    "            env.seed(i)\n",
    "            online_env.seed(i)\n",
    "\n",
    "            self.set_engine()\n",
    "\n",
    "            self.engine.fit(dataset, n_steps=n_steps, save_interval=save_interval, save_metrics=save_metrics, verbose=verbose)\n",
    "            self.engine.save_model(\"./saved_models/iql_{}_{}_{}.pt\".format(algo, task, i))\n",
    "            scorer = evaluate_on_environment(online_env, n_trials=100)\n",
    "            self.mean_results.append(scorer(self.engine))\n",
    "        return self.mean_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load datafile: 100%|██████████| 21/21 [00:13<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-18 17:28:11 [debug    ] RandomIterator is selected.\n",
      "2023-06-18 17:28:11 [debug    ] Building models...\n",
      "2023-06-18 17:28:15 [debug    ] Models have been built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 1/1 [00:02<00:00,  2.93s/it, critic_loss=42.9, value_loss=0.129, actor_loss=46.4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1.714704872094834]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = \"halfcheetah-medium-v2\"\n",
    "algo = \"IQL\"\n",
    "model = MODEL(task, algo)\n",
    "mean_results = model.train(n=1, n_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load datafile: 100%|██████████| 21/21 [01:57<00:00,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-16 21:41:47 [debug    ] RoundIterator is selected.\n",
      "2023-06-16 21:41:47 [info     ] Directory is created at d3rlpy_logs/MOPO_20230616214147\n",
      "2023-06-16 21:41:47 [warning  ] Skip building models since they're already built.\n",
      "2023-06-16 21:41:48 [info     ] Parameters are saved to d3rlpy_logs/MOPO_20230616214147/params.json params={'action_scaler': None, 'actor_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'actor_learning_rate': 0.0003, 'actor_optim_factory': {'optim_cls': 'Adam', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}, 'batch_size': 100, 'critic_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'critic_learning_rate': 0.0003, 'critic_optim_factory': {'optim_cls': 'Adam', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}, 'gamma': 0.99, 'generated_maxlen': 1250000, 'initial_temperature': 1.0, 'lam': 1.0, 'n_critics': 2, 'n_frames': 1, 'n_steps': 1, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'real_ratio': 0.05, 'reward_scaler': None, 'rollout_batch_size': 50000, 'rollout_horizon': 5, 'rollout_interval': 1000, 'scaler': None, 'tau': 0.005, 'temp_learning_rate': 0.0003, 'temp_optim_factory': {'optim_cls': 'Adam', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}, 'update_actor_interval': 1, 'use_gpu': None, 'algorithm': 'MOPO', 'observation_shape': (17,), 'action_size': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 0/9990 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The neural network parameters are not initialized. Pleaes call build_with_dataset, build_with_env, or directly call fit or fit_online method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m algo \u001b[39m=\u001b[39m d3rlpy\u001b[39m.\u001b[39malgos\u001b[39m.\u001b[39mMOPO(dynamics\u001b[39m=\u001b[39mdynamics)\n\u001b[1;32m     12\u001b[0m algo\u001b[39m.\u001b[39mbuild_with_dataset(dataset)\n\u001b[0;32m---> 13\u001b[0m algo\u001b[39m.\u001b[39;49mfit(dataset, n_epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, n_steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/msc_project/lib/python3.10/site-packages/d3rlpy/base.py:406\u001b[0m, in \u001b[0;36mLearnableBase.fit\u001b[0;34m(self, dataset, n_epochs, n_steps, n_steps_per_epoch, save_metrics, experiment_name, with_timestamp, logdir, verbose, show_progress, tensorboard_dir, eval_episodes, save_interval, scorers, shuffle, callback)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m    350\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    351\u001b[0m     dataset: Union[List[Episode], List[Transition], MDPDataset],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m     callback: Optional[Callable[[\u001b[39m\"\u001b[39m\u001b[39mLearnableBase\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m], \u001b[39mNone\u001b[39;00m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    369\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Tuple[\u001b[39mint\u001b[39m, Dict[\u001b[39mstr\u001b[39m, \u001b[39mfloat\u001b[39m]]]:\n\u001b[1;32m    370\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Trains with the given dataset.\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \n\u001b[1;32m    372\u001b[0m \u001b[39m    .. code-block:: python\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    404\u001b[0m \n\u001b[1;32m    405\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\n\u001b[1;32m    407\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfitter(\n\u001b[1;32m    408\u001b[0m             dataset,\n\u001b[1;32m    409\u001b[0m             n_epochs,\n\u001b[1;32m    410\u001b[0m             n_steps,\n\u001b[1;32m    411\u001b[0m             n_steps_per_epoch,\n\u001b[1;32m    412\u001b[0m             save_metrics,\n\u001b[1;32m    413\u001b[0m             experiment_name,\n\u001b[1;32m    414\u001b[0m             with_timestamp,\n\u001b[1;32m    415\u001b[0m             logdir,\n\u001b[1;32m    416\u001b[0m             verbose,\n\u001b[1;32m    417\u001b[0m             show_progress,\n\u001b[1;32m    418\u001b[0m             tensorboard_dir,\n\u001b[1;32m    419\u001b[0m             eval_episodes,\n\u001b[1;32m    420\u001b[0m             save_interval,\n\u001b[1;32m    421\u001b[0m             scorers,\n\u001b[1;32m    422\u001b[0m             shuffle,\n\u001b[1;32m    423\u001b[0m             callback,\n\u001b[1;32m    424\u001b[0m         )\n\u001b[1;32m    425\u001b[0m     )\n\u001b[1;32m    426\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/envs/msc_project/lib/python3.10/site-packages/d3rlpy/base.py:619\u001b[0m, in \u001b[0;36mLearnableBase.fitter\u001b[0;34m(self, dataset, n_epochs, n_steps, n_steps_per_epoch, save_metrics, experiment_name, with_timestamp, logdir, verbose, show_progress, tensorboard_dir, eval_episodes, save_interval, scorers, shuffle, callback)\u001b[0m\n\u001b[1;32m    614\u001b[0m iterator\u001b[39m.\u001b[39mreset()\n\u001b[1;32m    616\u001b[0m \u001b[39mfor\u001b[39;00m itr \u001b[39min\u001b[39;00m range_gen:\n\u001b[1;32m    617\u001b[0m \n\u001b[1;32m    618\u001b[0m     \u001b[39m# generate new transitions with dynamics models\u001b[39;00m\n\u001b[0;32m--> 619\u001b[0m     new_transitions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_new_data(\n\u001b[1;32m    620\u001b[0m         transitions\u001b[39m=\u001b[39;49miterator\u001b[39m.\u001b[39;49mtransitions,\n\u001b[1;32m    621\u001b[0m     )\n\u001b[1;32m    622\u001b[0m     \u001b[39mif\u001b[39;00m new_transitions:\n\u001b[1;32m    623\u001b[0m         iterator\u001b[39m.\u001b[39madd_generated_transitions(new_transitions)\n",
      "File \u001b[0;32m~/miniconda3/envs/msc_project/lib/python3.10/site-packages/d3rlpy/algos/utility.py:36\u001b[0m, in \u001b[0;36mModelBaseMixin.generate_new_data\u001b[0;34m(self, transitions)\u001b[0m\n\u001b[1;32m     33\u001b[0m prev_transitions: List[Transition] \u001b[39m=\u001b[39m []\n\u001b[1;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_rollout_horizon()):\n\u001b[1;32m     35\u001b[0m     \u001b[39m# predict next state\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dynamics\u001b[39m.\u001b[39;49mpredict(observations, actions, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     37\u001b[0m     pred \u001b[39m=\u001b[39m cast(Tuple[np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mndarray], pred)\n\u001b[1;32m     38\u001b[0m     next_observations, rewards, variances \u001b[39m=\u001b[39m pred\n",
      "File \u001b[0;32m~/miniconda3/envs/msc_project/lib/python3.10/site-packages/d3rlpy/dynamics/base.py:69\u001b[0m, in \u001b[0;36mDynamicsBase.predict\u001b[0;34m(self, x, action, with_variance, indices)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[1;32m     48\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     49\u001b[0m     x: Union[np\u001b[39m.\u001b[39mndarray, List[Any]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     Tuple[np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mndarray], Tuple[np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mndarray]\n\u001b[1;32m     55\u001b[0m ]:\n\u001b[1;32m     56\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns predicted observation and reward.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \n\u001b[1;32m     58\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, IMPL_NOT_INITIALIZED_ERROR\n\u001b[1;32m     70\u001b[0m     observations, rewards, variances \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl\u001b[39m.\u001b[39mpredict(\n\u001b[1;32m     71\u001b[0m         x,\n\u001b[1;32m     72\u001b[0m         action,\n\u001b[1;32m     73\u001b[0m         indices,\n\u001b[1;32m     74\u001b[0m     )\n\u001b[1;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m with_variance:\n",
      "\u001b[0;31mAssertionError\u001b[0m: The neural network parameters are not initialized. Pleaes call build_with_dataset, build_with_env, or directly call fit or fit_online method."
     ]
    }
   ],
   "source": [
    "import d3rlpy\n",
    "from d3rlpy.datasets import get_d4rl\n",
    "from d3rlpy.dynamics.base import DynamicsBase\n",
    "import gym\n",
    "\n",
    "task = \"halfcheetah-medium-v2\"\n",
    "dataset, env = get_d4rl(task)\n",
    "online_env = gym.make(task)\n",
    "\n",
    "dynamics = DynamicsBase(batch_size=256, reward_scaler=None, n_frames=1, scaler=None, action_scaler=None, kwargs=None)\n",
    "algo = d3rlpy.algos.MOPO(dynamics=dynamics)\n",
    "algo.build_with_dataset(dataset)\n",
    "algo.fit(dataset, n_epochs=2, n_steps_per_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
