{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raunakk/miniconda3/envs/msc_project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n",
      "pybullet build time: Jun 13 2023 11:48:14\n",
      "/home/raunakk/miniconda3/envs/msc_project/lib/python3.10/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "load datafile: 100%|██████████| 9/9 [00:14<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-07-14 18:05:09\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mRoundIterator is selected.\u001b[0m\n",
      "\u001b[2m2023-07-14 18:05:09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/COMBO_halfcheetah-medium-expert-v2\u001b[0m\n",
      "\u001b[2m2023-07-14 18:05:09\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...\u001b[0m\n",
      "\u001b[2m2023-07-14 18:06:46\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 14985/14985 [16:38<00:00, 15.01it/s, loss=-7.32]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-07-14 18:23:27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/COMBO_halfcheetah-medium-expert-v2/model_14985.pt\u001b[0m\n",
      "\u001b[2m2023-07-14 18:23:28\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mUnused arguments are passed.  \u001b[0m \u001b[36malgorithm\u001b[0m=\u001b[35mProbabilisticEnsembleDynamics\u001b[0m \u001b[36mgamma\u001b[0m=\u001b[35m1.0\u001b[0m \u001b[36mgenerated_maxlen\u001b[0m=\u001b[35m100000\u001b[0m \u001b[36mn_steps\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mreal_ratio\u001b[0m=\u001b[35m1.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "'''This file trains using MOPO and COMBO algorithm'''\n",
    "\n",
    "#This training script generates multiple trajectories and notes the score. So, we get 100 scores instead of noting just the mean score.\n",
    "\n",
    "import d3rlpy\n",
    "from d3rlpy.datasets import get_d4rl\n",
    "import gym\n",
    "from d3rlpy.metrics.scorer import evaluate_on_environment\n",
    "from d3rlpy.dynamics import ProbabilisticEnsembleDynamics\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import argparse\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "#import wandb\n",
    "\n",
    "#wandb.login()\n",
    "\n",
    "\n",
    "os.environ['D4RL_SUPPRESS_IMPORT_ERROR'] = '1'\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--task\", type=str, help=\"task/game to be played\")\n",
    "# parser.add_argument(\"--algo\", type=str, help=\"algorithm to be used for training\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "task = 'halfcheetah-medium-expert-v2' #args.task \n",
    "algo = 'COMBO' #args.algo\n",
    "\n",
    "\"\"\"\n",
    "suggested hypers for combo\n",
    "\n",
    "halfcheetah-medium-v2: rollout-length=5, cql-weight=0.5\n",
    "hopper-medium-v2: rollout-length=5, cql-weight=5.0\n",
    "walker2d-medium-v2: rollout-length=1, cql-weight=5.0\n",
    "halfcheetah-medium-replay-v2: rollout-length=5, cql-weight=0.5\n",
    "hopper-medium-replay-v2: rollout-length=5, cql-weight=0.5\n",
    "walker2d-medium-replay-v2: rollout-length=1, cql-weight=0.5\n",
    "halfcheetah-medium-expert-v2: rollout-length=5, cql-weight=5.0\n",
    "hopper-medium-expert-v2: rollout-length=5, cql-weight=5.0\n",
    "walker2d-medium-expert-v2: rollout-length=1, cql-weight=5.0\n",
    "\n",
    "suggested hypers for mopo\n",
    "\n",
    "halfcheetah-medium-v2: rollout-length=5, penalty-coef=0.5\n",
    "hopper-medium-v2: rollout-length=5, penalty-coef=5.0\n",
    "walker2d-medium-v2: rollout-length=5, penalty-coef=0.5\n",
    "halfcheetah-medium-replay-v2: rollout-length=5, penalty-coef=0.5\n",
    "hopper-medium-replay-v2: rollout-length=5, penalty-coef=2.5\n",
    "walker2d-medium-replay-v2: rollout-length=1, penalty-coef=2.5\n",
    "halfcheetah-medium-expert-v2: rollout-length=5, penalty-coef=2.5\n",
    "hopper-medium-expert-v2: rollout-length=5, penalty-coef=5.0\n",
    "walker2d-medium-expert-v2: rollout-length=1, penalty-coef=2.5\n",
    "\"\"\"\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, task, algo, gpu=True):\n",
    "        self.task = task \n",
    "        self.algo = algo\n",
    "        self.dynamics = None\n",
    "        self.f_params = {}\n",
    "        self.experiment_name = f\"{self.algo}_{self.task}\"\n",
    "\n",
    "    def set_engine(self):\n",
    "        if self.algo == \"MOPO\":\n",
    "            if self.algo == \"halfcheetah-medium-v2\" or self.algo == \"halfcheetah-medium-replay-v2\" or self.algo == \"walker2d-medium-v2\":\n",
    "                self.f_params = {'rollout_length': 5, 'penalty_coef': 0.5}\n",
    "            elif self.algo == \"hopper-medium-v2\" or self.algo == \"hopper-medium-expert-v2\":\n",
    "                self.f_params = {'rollout_length': 5, 'penalty_coef': 5.0}\n",
    "            elif self.algo == \"hopper-medium-replay-v2\" or self.algo == \"halfcheetah-medium-expert-v2\":\n",
    "                self.f_params = {'rollout_length': 5, 'penalty_coef': 2.5}\n",
    "            elif self.algo == \"walker2d-medium-replay-v2\" or self.algo == \"walker2d-medium-expert-v2\":\n",
    "                self.f_params = {'rollout_length': 1, 'penalty_coef': 2.5}            \n",
    "\n",
    "            self.engine = d3rlpy.algos.MOPO(dynamics=self.dynamics, **self.f_params)     \n",
    "\n",
    "        elif self.algo == \"COMBO\":\n",
    "            if self.algo == \"halfcheetah-medium-v2\" or self.algo == \"halfcheetah-medium-replay-v2\" or self.algo == \"hopper-medium-replay-v2\":\n",
    "                self.f_params = {'rollout_length': 5, 'cql_weight': 0.5}\n",
    "            elif self.algo == \"hopper-medium-v2\" or self.algo == \"hopper-medium-expert-v2\" or self.algo == \"halfcheetah-medium-expert-v2\":\n",
    "                self.f_params = {'rollout_length': 5, 'cql_weight': 5.0}\n",
    "            elif self.algo == \"walker2d-medium-v2\" or self.algo == \"walker2d-medium-expert-v2\":\n",
    "                self.f_params = {'rollout_length': 1, 'cql_weight': 5.0}\n",
    "            elif self.algo == \"walker2d-medium-replay-v2\":\n",
    "                self.f_params = {'rollout_length': 1, 'cql_weight': 0.5}\n",
    "\n",
    "            self.engine = d3rlpy.algos.COMBO(dynamics=self.dynamics, **self.f_params)\n",
    "        \n",
    "\n",
    "    def train_dynamics(self, n_epochs=100, save_interval=100, save_metrics=True, verbose=False, with_timestamp=False):\n",
    "        self.dynamics = d3rlpy.dynamics.ProbabilisticEnsembleDynamics(learning_rate=1e-4, use_gpu=True)\n",
    "        train_episodes, test_episodes = train_test_split(self.dataset)\n",
    "        self.dynamics.fit(train_episodes, eval_episodes=test_episodes, n_epochs=n_epochs, \n",
    "        save_interval=save_interval, save_metrics=save_metrics, verbose=verbose, with_timestamp=with_timestamp, experiment_name=self.experiment_name)\n",
    "            \n",
    "\n",
    "    def train_engine(self, n_steps=1000000, save_interval=101, save_metrics=False, verbose=False):\n",
    "        self.set_engine()\n",
    "        self.engine.fit(self.dataset, n_steps=n_steps, save_interval=save_interval, save_metrics=save_metrics, verbose=verbose)\n",
    "    \n",
    "    def train(self, n=50, n_epochs=100, n_steps=1000000, save_engine_interval=100, save_dynamics_interval=100,\n",
    "               save_dynamics_metrics=True, save_engine_metrics=False, verbose=False, with_timestamp=False):\n",
    "        for i in range(n):\n",
    "            self.dataset, self.env = get_d4rl(self.task)\n",
    "            self.online_env = gym.make(self.task)\n",
    "            d3rlpy.seed(i)\n",
    "            self.env.reset(seed=i)\n",
    "            self.online_env.reset(seed=i)\n",
    "\n",
    "            self.train_dynamics(n_epochs=n_epochs, save_interval=save_dynamics_interval, save_metrics=save_dynamics_metrics, verbose=verbose, with_timestamp=with_timestamp)\n",
    "            # load trained dynamics model\n",
    "            json_path = f'./d3rlpy_logs/{self.experiment_name}/params.json'\n",
    "            source_directory = f'./d3rlpy_logs/{self.experiment_name}'\n",
    "            keyword = \"model\"\n",
    "\n",
    "            # Iterate over each file in the directory\n",
    "            for root, dirs, files in os.walk(source_directory):\n",
    "                for filename in files:\n",
    "                    # Check if the file name contains the keyword \"model\"\n",
    "                    if keyword in filename:\n",
    "                        # Get the full path of the file\n",
    "                        model_path = os.path.join(root, filename)\n",
    "\t\t    \t\t    \n",
    "            self.dynamics = ProbabilisticEnsembleDynamics.from_json(json_path)\n",
    "            self.dynamics.load_model(model_path)\n",
    "            self.train_engine(n_steps=n_steps, save_interval=save_engine_interval, save_metrics=save_engine_metrics, verbose=verbose)\n",
    "            scorer = evaluate_on_environment(self.online_env, n_trials=1)\n",
    "            f = open(f'./txt_files/{algo}_{task}_rollout.txt', 'a+')\n",
    "            f.write(f\"n={i}\\n\")\n",
    "\n",
    "            for i in range(1000):       \n",
    "                normalized_score = self.online_env.get_normalized_score(scorer(self.engine))\n",
    "                f = open(f'./txt_files/{algo}_{task}_rollout.txt', 'a+')\n",
    "                f.write(f\"{normalized_score}\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "model = Model(task, algo)\n",
    "model.train(n=1, n_epochs=1, save_dynamics_interval=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raunakk/miniconda3/envs/msc_project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n",
      "pybullet build time: Jun 13 2023 11:48:14\n",
      "/home/raunakk/miniconda3/envs/msc_project/lib/python3.10/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "load datafile: 100%|██████████| 9/9 [00:10<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\u001b[2m2023-07-14 18:45:54\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mUnused arguments are passed.  \u001b[0m \u001b[36malgorithm\u001b[0m=\u001b[35mProbabilisticEnsembleDynamics\u001b[0m \u001b[36mgamma\u001b[0m=\u001b[35m1.0\u001b[0m \u001b[36mgenerated_maxlen\u001b[0m=\u001b[35m100000\u001b[0m \u001b[36mn_steps\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mreal_ratio\u001b[0m=\u001b[35m1.0\u001b[0m\n",
      "\u001b[2m2023-07-14 18:46:04\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mRandomIterator is selected.\u001b[0m\n",
      "\u001b[2m2023-07-14 18:46:04\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...\u001b[0m\n",
      "\u001b[2m2023-07-14 18:46:05\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-07-14 18:46:13\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1m250000 transitions are generated.\u001b[0m \u001b[36mfake_transitions\u001b[0m=\u001b[35m250000\u001b[0m \u001b[36mreal_transitions\u001b[0m=\u001b[35m1998000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  10%|▉         | 999/10000 [01:18<09:37, 15.60it/s, critic_loss=15.6, actor_loss=-24, temp_loss=8.99, temp=0.953]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-07-14 18:47:29\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1m250000 transitions are generated.\u001b[0m \u001b[36mfake_transitions\u001b[0m=\u001b[35m500000\u001b[0m \u001b[36mreal_transitions\u001b[0m=\u001b[35m1998000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  20%|█▉        | 1999/10000 [02:29<08:27, 15.76it/s, critic_loss=13.8, actor_loss=-38.5, temp_loss=7.87, temp=0.913]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-07-14 18:48:39\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1m250000 transitions are generated.\u001b[0m \u001b[36mfake_transitions\u001b[0m=\u001b[35m750000\u001b[0m \u001b[36mreal_transitions\u001b[0m=\u001b[35m1998000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  30%|██▉       | 2999/10000 [03:45<08:00, 14.56it/s, critic_loss=13.9, actor_loss=-54.1, temp_loss=6.94, temp=0.876]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-07-14 18:49:58\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1m250000 transitions are generated.\u001b[0m \u001b[36mfake_transitions\u001b[0m=\u001b[35m1000000\u001b[0m \u001b[36mreal_transitions\u001b[0m=\u001b[35m1998000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  40%|███▉      | 3999/10000 [05:07<07:00, 14.26it/s, critic_loss=14.8, actor_loss=-70.8, temp_loss=6.14, temp=0.844]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-07-14 18:51:20\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1m250000 transitions are generated.\u001b[0m \u001b[36mfake_transitions\u001b[0m=\u001b[35m1250000\u001b[0m \u001b[36mreal_transitions\u001b[0m=\u001b[35m1998000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  50%|█████     | 5000/10000 [06:32<05:35, 14.92it/s, critic_loss=16.5, actor_loss=-88.3, temp_loss=5.46, temp=0.814]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "'''This file trains using MOPO and COMBO algorithm'''\n",
    "\n",
    "#This training script generates multiple trajectories and notes the score. So, we get 100 scores instead of noting just the mean score.\n",
    "\n",
    "import d3rlpy\n",
    "from d3rlpy.datasets import get_d4rl\n",
    "import gym\n",
    "from d3rlpy.metrics.scorer import evaluate_on_environment\n",
    "from d3rlpy.dynamics import ProbabilisticEnsembleDynamics\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import argparse\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "#import wandb\n",
    "\n",
    "#wandb.login()\n",
    "\n",
    "\n",
    "os.environ['D4RL_SUPPRESS_IMPORT_ERROR'] = '1'\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--task\", type=str, help=\"task/game to be played\")\n",
    "# parser.add_argument(\"--algo\", type=str, help=\"algorithm to be used for training\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "task = 'halfcheetah-medium-expert-v2' #args.task \n",
    "algo = 'COMBO' #args.algo\n",
    "\n",
    "\"\"\"\n",
    "suggested hypers for combo\n",
    "\n",
    "halfcheetah-medium-v2: rollout-length=5, cql-weight=0.5\n",
    "hopper-medium-v2: rollout-length=5, cql-weight=5.0\n",
    "walker2d-medium-v2: rollout-length=1, cql-weight=5.0\n",
    "halfcheetah-medium-replay-v2: rollout-length=5, cql-weight=0.5\n",
    "hopper-medium-replay-v2: rollout-length=5, cql-weight=0.5\n",
    "walker2d-medium-replay-v2: rollout-length=1, cql-weight=0.5\n",
    "halfcheetah-medium-expert-v2: rollout-length=5, cql-weight=5.0\n",
    "hopper-medium-expert-v2: rollout-length=5, cql-weight=5.0\n",
    "walker2d-medium-expert-v2: rollout-length=1, cql-weight=5.0\n",
    "\n",
    "suggested hypers for mopo\n",
    "\n",
    "halfcheetah-medium-v2: rollout-length=5, penalty-coef=0.5\n",
    "hopper-medium-v2: rollout-length=5, penalty-coef=5.0\n",
    "walker2d-medium-v2: rollout-length=5, penalty-coef=0.5\n",
    "halfcheetah-medium-replay-v2: rollout-length=5, penalty-coef=0.5\n",
    "hopper-medium-replay-v2: rollout-length=5, penalty-coef=2.5\n",
    "walker2d-medium-replay-v2: rollout-length=1, penalty-coef=2.5\n",
    "halfcheetah-medium-expert-v2: rollout-length=5, penalty-coef=2.5\n",
    "hopper-medium-expert-v2: rollout-length=5, penalty-coef=5.0\n",
    "walker2d-medium-expert-v2: rollout-length=1, penalty-coef=2.5\n",
    "\"\"\"\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, task, algo, gpu=True):\n",
    "        self.task = task \n",
    "        self.algo = algo\n",
    "        self.dynamics = None\n",
    "        self.f_params = {}\n",
    "        self.experiment_name = f\"{self.algo}_{self.task}\"\n",
    "\n",
    "    def set_engine(self):\n",
    "        if self.algo == \"MOPO\":\n",
    "            if self.algo == \"halfcheetah-medium-v2\" or self.algo == \"halfcheetah-medium-replay-v2\" or self.algo == \"walker2d-medium-v2\":\n",
    "                self.f_params = {'rollout_length': 5, 'penalty_coef': 0.5}\n",
    "            elif self.algo == \"hopper-medium-v2\" or self.algo == \"hopper-medium-expert-v2\":\n",
    "                self.f_params = {'rollout_length': 5, 'penalty_coef': 5.0}\n",
    "            elif self.algo == \"hopper-medium-replay-v2\" or self.algo == \"halfcheetah-medium-expert-v2\":\n",
    "                self.f_params = {'rollout_length': 5, 'penalty_coef': 2.5}\n",
    "            elif self.algo == \"walker2d-medium-replay-v2\" or self.algo == \"walker2d-medium-expert-v2\":\n",
    "                self.f_params = {'rollout_length': 1, 'penalty_coef': 2.5}            \n",
    "\n",
    "            self.engine = d3rlpy.algos.MOPO(dynamics=self.dynamics, **self.f_params)     \n",
    "\n",
    "        elif self.algo == \"COMBO\":\n",
    "            if self.algo == \"halfcheetah-medium-v2\" or self.algo == \"halfcheetah-medium-replay-v2\" or self.algo == \"hopper-medium-replay-v2\":\n",
    "                self.f_params = {'rollout_length': 5, 'cql_weight': 0.5}\n",
    "            elif self.algo == \"hopper-medium-v2\" or self.algo == \"hopper-medium-expert-v2\" or self.algo == \"halfcheetah-medium-expert-v2\":\n",
    "                self.f_params = {'rollout_length': 5, 'cql_weight': 5.0}\n",
    "            elif self.algo == \"walker2d-medium-v2\" or self.algo == \"walker2d-medium-expert-v2\":\n",
    "                self.f_params = {'rollout_length': 1, 'cql_weight': 5.0}\n",
    "            elif self.algo == \"walker2d-medium-replay-v2\":\n",
    "                self.f_params = {'rollout_length': 1, 'cql_weight': 0.5}\n",
    "\n",
    "            self.engine = d3rlpy.algos.COMBO(dynamics=self.dynamics, **self.f_params)\n",
    "        \n",
    "\n",
    "    def train_dynamics(self, n_epochs=100, save_interval=100, save_metrics=True, verbose=False, with_timestamp=False):\n",
    "        self.dynamics = d3rlpy.dynamics.ProbabilisticEnsembleDynamics(learning_rate=1e-4, use_gpu=True)\n",
    "        train_episodes, test_episodes = train_test_split(self.dataset)\n",
    "        self.dynamics.fit(train_episodes, eval_episodes=test_episodes, n_epochs=n_epochs, \n",
    "        save_interval=save_interval, save_metrics=save_metrics, verbose=verbose, with_timestamp=with_timestamp, experiment_name=self.experiment_name)\n",
    "            \n",
    "\n",
    "    def train_engine(self, n_steps=1000000, save_interval=101, save_metrics=False, verbose=False):\n",
    "        self.set_engine()\n",
    "        self.engine.fit(self.dataset, n_steps=n_steps, save_interval=save_interval, save_metrics=save_metrics, verbose=verbose)\n",
    "    \n",
    "    def train(self, n=50, n_epochs=100, n_steps=1000000, save_engine_interval=100, save_dynamics_interval=100,\n",
    "               save_dynamics_metrics=True, save_engine_metrics=False, verbose=False, with_timestamp=False):\n",
    "        for i in range(n):\n",
    "            self.dataset, self.env = get_d4rl(self.task)\n",
    "            self.online_env = gym.make(self.task)\n",
    "            d3rlpy.seed(i)\n",
    "            self.env.reset(seed=i)\n",
    "            self.online_env.reset(seed=i)\n",
    "\n",
    "            # self.train_dynamics(n_epochs=n_epochs, save_interval=save_dynamics_interval, save_metrics=save_dynamics_metrics, verbose=verbose, with_timestamp=with_timestamp)\n",
    "            # load trained dynamics model\n",
    "            json_path = f'./d3rlpy_logs/{self.experiment_name}/params.json'\n",
    "            source_directory = f'./d3rlpy_logs/{self.experiment_name}'\n",
    "            keyword = \"model\"\n",
    "            print(1)\n",
    "\n",
    "            # Iterate over each file in the directory\n",
    "            for root, dirs, files in os.walk(source_directory):\n",
    "                for filename in files:\n",
    "                    # Check if the file name contains the keyword \"model\"\n",
    "                    if keyword in filename:\n",
    "                        # Get the full path of the file\n",
    "                        model_path = os.path.join(root, filename)\n",
    "\t\t    \t\t    \n",
    "            self.dynamics = ProbabilisticEnsembleDynamics.from_json(json_path)\n",
    "            self.dynamics.load_model(model_path)\n",
    "            self.train_engine(n_steps=n_steps, save_interval=save_engine_interval, save_metrics=save_engine_metrics, verbose=verbose)\n",
    "            scorer = evaluate_on_environment(self.online_env, n_trials=1)\n",
    "            f = open(f'./txt_files/{algo}_{task}_rollout.txt', 'a+')\n",
    "            f.write(f\"n={i}\\n\")\n",
    "\n",
    "            for i in range(1000):       \n",
    "                normalized_score = self.online_env.get_normalized_score(scorer(self.engine))\n",
    "                f = open(f'./txt_files/{algo}_{task}_rollout.txt', 'a+')\n",
    "                f.write(f\"{normalized_score}\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "model = Model(task, algo)\n",
    "model.train(n=1, n_epochs=1, n_steps=10000, save_dynamics_interval=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
